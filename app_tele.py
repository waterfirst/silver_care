import streamlit as st
import streamlit.components.v1 as components
from openai import OpenAI
import base64
from datetime import datetime
import telebot
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¤ë²„ì¼€ì–´ ìŒì„± ë¹„ì„œ",
    page_icon="ğŸ¤",
    layout="wide"
)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])

# í…”ë ˆê·¸ë¨ ë´‡ ì„¤ì •
TELEGRAM_TOKEN = st.secrets["TELEGRAM_TOKEN"]
TELEGRAM_CHAT_ID = st.secrets.get("TELEGRAM_CHAT_ID", "your_default_chat_id")
bot = telebot.TeleBot(TELEGRAM_TOKEN)

# ìŒì„± ì¸ì‹ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
def init_speech_recognition():
    components.html(
        """
        <script>
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.lang = 'ko-KR';
        recognition.continuous = false;
        recognition.interimResults = false;

        recognition.onresult = (event) => {
            const text = event.results[0][0].transcript;
            window.parent.postMessage({
                type: 'speech-recognition',
                text: text
            }, '*');
        };

        window.startRecognition = () => {
            recognition.start();
        }
        </script>
        <button onclick="startRecognition()" class="stButton">
            ğŸ¤ ìŒì„±ìœ¼ë¡œ ë§í•˜ê¸°
        </button>
        """,
        height=50
    )

# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
def text_to_speech(text, voice="shimmer"):
    try:
        response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode()
        
        # HTML ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ìƒì„±
        audio_html = f'''
            <audio autoplay="true" controls>
                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
            </audio>
        '''
        st.components.v1.html(audio_html, height=50)
        return True
    except Exception as e:
        st.error(f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {e}")
        return False

# GPT ì‘ë‹µ ìƒì„±
@st.cache_data(ttl=3600)
def generate_response(prompt):
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=150
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"GPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ê¸´ê¸‰ ì•Œë¦¼ ì „ì†¡
def send_emergency_alert():
    try:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        message = f"""ğŸš¨ ê¸´ê¸‰ ìƒí™© ë°œìƒ!
ë°œìƒ ì‹œê°„: {current_time}
ìƒí™©: ê¸´ê¸‰ ë„ì›€ ìš”ì²­
"""
        bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message)
        return True
    except Exception as e:
        st.error(f"í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
        return False

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    voice_option = st.radio(
        "ìŒì„± ì„ íƒ",
        ["ì—¬ì„± (shimmer)", "ë‚¨ì„± (onyx)"],
        index=0
    )
    
    # ìŒëŸ‰ ì„¤ì •
    volume = st.slider("ìŒëŸ‰", 0, 100, 50)
    
    st.divider()
    
    # ê¸´ê¸‰ ì—°ë½ ì„¹ì…˜
    st.markdown("### âš ï¸ ê¸´ê¸‰ ì—°ë½")
    if st.button("ğŸš¨ ê¸´ê¸‰ ë„ì›€ ìš”ì²­", use_container_width=True):
        with st.spinner("ê¸´ê¸‰ ì•Œë¦¼ ì „ì†¡ ì¤‘..."):
            if send_emergency_alert():
                st.success("ê¸´ê¸‰ ì•Œë¦¼ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
                text_to_speech(
                    "ê¸´ê¸‰ ì•Œë¦¼ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ê³§ ë„ì›€ì´ ë„ì°©í•  ì˜ˆì •ì…ë‹ˆë‹¤."
                )
            else:
                st.error("ê¸´ê¸‰ ì•Œë¦¼ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í™”ë©´
st.title("ğŸ¤ ì‹¤ë²„ì¼€ì–´ ìŒì„± ë¹„ì„œ")

# ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
init_speech_recognition()

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬
    with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
        response = generate_response(prompt)
        if response:
            st.session_state.messages.append(
                {"role": "assistant", "content": response}
            )
            with st.chat_message("assistant"):
                st.markdown(response)
            
            # ìŒì„± ë³€í™˜ ë° ì¬ìƒ
            voice = "shimmer" if "ì—¬ì„±" in voice_option else "onyx"
            text_to_speech(response, voice)

# í•˜ë‹¨ ì •ë³´
st.divider()
col1, col2, col3 = st.columns(3)

with col1:
    st.info("ğŸ“… ì˜¤ëŠ˜ì˜ ì¼ì •")
    st.write("- ì˜¤í›„ 3ì‹œ: ë³‘ì› ì˜ˆì•½")
    st.write("- ì €ë… 6ì‹œ: ë³µì•½ ì‹œê°„")

with col2:
    st.success("ğŸ’Š ë³µì•½ ê´€ë¦¬")
    st.write("- í˜ˆì••ì•½: ì•„ì¹¨/ì €ë… ì‹í›„ 30ë¶„")
    st.write("- ë¹„íƒ€ë¯¼: ì•„ì¹¨ ì‹ì „")

with col3:
    st.warning("âš¡ ê¸´ê¸‰ ìƒí™© ì‹œ")
    st.write("1. ê¸´ê¸‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
    st.write("2. ë„ì›€ ìš”ì²­ì´ ìë™ ì „ì†¡ë©ë‹ˆë‹¤")
    st.write("3. ì¹¨ì°©í•˜ê²Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”")
